{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJV-TQ_UVyMr"
      },
      "source": [
        "# Analisis preeliminar de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ly_FJ3Wl1Gw"
      },
      "source": [
        "## Importación de los datos desde Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lzLnkSbbuxN8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle wavio pydub keras-metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D3DLGLOSl7VF"
      },
      "outputs": [],
      "source": [
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuración de la fuente de datos"
      ],
      "metadata": {
        "id": "nX9tOOFikWRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggle\n",
        "# processed\n",
        "# processed_augmented\n",
        "data_source = 'processed'\n",
        "os.environ[\"DATA_SOURCE\"] = data_source"
      ],
      "metadata": {
        "id": "cJGmZqHokdWT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf *\n",
        "\n",
        "if [ \"$DATA_SOURCE\" == \"kaggle\" ];\n",
        "then\n",
        "mkdir ~/.kaggle\n",
        "curl https://raw.githubusercontent.com/Solrak97/clasificador_de_sentimientos/main/kaggle.json > kaggle.json\n",
        "cp kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "kaggle datasets download uwrfkaggler/ravdess-emotional-speech-audio\n",
        "unzip ravdess-emotional-speech-audio.zip\n",
        "fi\n",
        "\n",
        "if [ \"$DATA_SOURCE\" == \"processed\" ];\n",
        "then\n",
        "curl https://raw.githubusercontent.com/Solrak97/clasificador_de_sentimientos/main/data.pkl > data.pkl\n",
        "fi\n",
        "\n",
        "if [ \"$DATA_SOURCE\" == \"processed_augmented\" ];\n",
        "then\n",
        "curl https://raw.githubusercontent.com/Solrak97/clasificador_de_sentimientos/main/data_augmentation.pkl > data.pkl\n",
        "fi"
      ],
      "metadata": {
        "id": "dA38PxMfk8ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parece que existen algunos problemas de overfitting por lo que decidimos crear un poco más de muestras con data augmentation a ver si sale"
      ],
      "metadata": {
        "id": "1-VBg_UH1cQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def cambio_velocidad(sound, speed=1.0):\n",
        "\n",
        "    sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
        "         \"frame_rate\": int(sound.frame_rate * speed)\n",
        "      })\n",
        "\n",
        "    return sound_with_altered_frame_rate.set_frame_rate(sound.frame_rate)"
      ],
      "metadata": {
        "id": "Bd8zvy681tlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if data_source == 'kaggle':\n",
        "\n",
        "  for file in glob.glob(\"Actor_*/*.wav\"):\n",
        "\n",
        "    file_name = os.path.basename(file)\n",
        "  \n",
        "    # El audio viene en estereo para algunas partes así que se pasa a mono\n",
        "    sound = AudioSegment.from_wav(file)\n",
        "    sound = sound.set_channels(1)\n",
        "    sound.export(file, format=\"wav\")\n",
        "\n",
        "    slow_sound = cambio_velocidad(sound, 0.81)\n",
        "\n",
        "    fast_sound = cambio_velocidad(sound, 1.23)\n",
        "\n",
        "    file = file.split(\".\")[0]\n",
        "    sound.export(f'{file}-FST.wav', format=\"wav\")\n",
        "    sound.export(f'{file}-SLW.wav', format=\"wav\")\n"
      ],
      "metadata": {
        "id": "B_2yQeSM1nyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jtAJAd1trCH"
      },
      "source": [
        "### Transformación de los datos a las caracteristicas base del estudio Dias Issa et al.\n",
        "Se extraerá un grupo de caracteristicas para analizar, hemos notado que hay diferencias en los tamaños de los audios por lo que hemos decidido revisar como funcionan correctamente los tamaños de datos y otras de estas caracteristicas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INT_2_EMOTION = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}"
      ],
      "metadata": {
        "id": "TsMfB3lK5RLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aJdzXuPtvlr"
      },
      "outputs": [],
      "source": [
        "name, _len, emotions, mfccs, chromas, mels, contrasts, tonnetz = [], [], [], [], [], [], [], []\n",
        "\n",
        "if data_source == 'kaggle':\n",
        "  for file in glob.glob(\"Actor_*/*.wav\"):\n",
        "      file_name = os.path.basename(file)\n",
        "\n",
        "      sound = AudioSegment.from_wav(file)\n",
        "      sound = sound.set_channels(1)\n",
        "      sound.export(file, format=\"wav\")\n",
        "\n",
        "      name_split = file_name.split(\"-\")\n",
        "      emotion = INT_2_EMOTION[name_split[2]]\n",
        "\n",
        "      with soundfile.SoundFile(file) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        stft = np.abs(librosa.stft(X))\n",
        "        mfccs.append(np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=84).T, axis=0))\n",
        "        chromas.append(np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0))\n",
        "        mels.append(np.mean(librosa.feature.melspectrogram(X, sr=sample_rate, n_mels=84).T,axis=0))\n",
        "        contrasts.append(np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0))\n",
        "        tonnetz.append(np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0))\n",
        "        \n",
        "        _len.append(librosa.get_duration(y=X, sr=sample_rate))         \n",
        "\n",
        "      name.append(file_name)\n",
        "      emotions.append(emotion)\n",
        "\n",
        "  data = pd.DataFrame({'File name': name, 'Emotion': emotions, 'Duration': _len,\n",
        "                        'MFCC': mfccs, 'Chroma': chromas, 'Mel': mels, 'Contrast': contrasts, 'Tonnetz': tonnetz})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if data_source == 'kaggle':\n",
        "  data.to_pickle('data.pkl')\n",
        "else:\n",
        "  data = pd.read_pickle('data.pkl')"
      ],
      "metadata": {
        "id": "ys9429NElPTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformación de los datos utilizando PCA"
      ],
      "metadata": {
        "id": "t91rBCyh9hZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Emotion', 'File name'])\n",
        "\n",
        "# Forgive me god, but it has to be done\n",
        "X = np.array([np.hstack([X['MFCC'][i], X['Chroma'][i], X['Mel'][i], \n",
        "                         X['Contrast'][i], X['Tonnetz'][i]]) for i in range(len(X.index))])"
      ],
      "metadata": {
        "id": "BSFJ8zmA9ZY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X) \n",
        "\n",
        "\n",
        "pca = PCA(3)\n",
        "reduced = pca.fit_transform(X)\n",
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "sruN7Czw612s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separación no supervisada como intento de visualizar los datos agrupados."
      ],
      "metadata": {
        "id": "-nEirhvGCRpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNv7Jb_suYsj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "label = KMeans(n_clusters=8, random_state=0).fit_predict(reduced)\n",
        "labeled_kmeans = pd.DataFrame({'X': reduced[:,0], 'Y': reduced[:,1], 'label': label, 'Emotion': data['Emotion']})\n",
        "\n",
        "\n",
        "filtered_label0 = reduced[label == 0]\n",
        "filtered_label0 = reduced[label == 1]\n",
        "filtered_label0 = reduced[label == 2]\n",
        "filtered_label0 = reduced[label == 3]\n",
        "filtered_label0 = reduced[label == 4]\n",
        "filtered_label0 = reduced[label == 5]\n",
        "filtered_label0 = reduced[label == 6]\n",
        "filtered_label0 = reduced[label == 7]\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=labeled_kmeans, x=\"X\", y=\"Y\", hue='Emotion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IwOXPSkk5iCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba de separación con el base model"
      ],
      "metadata": {
        "id": "AaXnNhO0NOGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dropout, MaxPool1D, Flatten, Dense, ReLU, Input, BatchNormalization, Softmax\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.advanced_activations import Softmax\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "metadata": {
        "id": "ePC9lniLNXOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_baseline():\n",
        "  model = Sequential()\n",
        "\n",
        "  # input layer\n",
        "  model.add(Input(shape=(193, 1)))\n",
        "  \n",
        "  # Primer Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=255, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "\n",
        "  # Segund Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  # Capa de Maxpooling\n",
        "  model.add(MaxPool1D(pool_size=8))\n",
        "\n",
        "  # 3 capas convolucionales intermedias\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa convolucional final\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa densa, tiene la misma cantidad de neuronas que de clases a predecir\n",
        "  model.add(Dense(units=8))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Softmax())  \n",
        "  return model"
      ],
      "metadata": {
        "id": "6mGSU-9aNSS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación de los datos"
      ],
      "metadata": {
        "id": "ru-ZZp03ONIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forgive me god, but it has to be done twice\n",
        "X = np.array([np.hstack([data['MFCC'][i], data['Chroma'][i], data['Mel'][i], \n",
        "                         data['Contrast'][i], data['Tonnetz'][i]]) for i in range(len(data.index))])\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)\n",
        "Y = np.array(data['Emotion'])\n",
        "\n",
        "# Codificación de one hot encoding\n",
        "encoder = OneHotEncoder()\n",
        "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "cIqobLbSNao-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento y predicciones"
      ],
      "metadata": {
        "id": "dPunUi4sOQUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_baseline()\n",
        "model.compile(optimizer = RMSprop(learning_rate=1e-5) , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "hpTUrO9IQUNt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, validation_split = 0.20, epochs=700, batch_size=100, verbose=False)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hy4Yd0p6OMSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "icpz76admoCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-K fold validation, 700 epochs"
      ],
      "metadata": {
        "id": "l0ZO2vrCfkx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold(size, k):\n",
        "  index = [i for i in range(size)]\n",
        "  index_reduct = index\n",
        "  splits = []\n",
        "  for i in range(k):\n",
        "    test = random.sample(index_reduct, round(size/k))\n",
        "    train = [x for x in index if x not in test]\n",
        "    index_reduct = [x for x in index_reduct if x not in test]\n",
        "    splits.append((train, test))\n",
        "  return splits\n",
        "    "
      ],
      "metadata": {
        "id": "jngaUdppbtzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([np.hstack([data['MFCC'][i], data['Chroma'][i], data['Mel'][i], \n",
        "                         data['Contrast'][i], data['Tonnetz'][i]]) for i in range(len(data.index))])\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)\n",
        "Y = np.array(data['Emotion'])\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
        "\n",
        "fold_idx = kfold(len(y), 5)\n",
        "\n",
        "\n",
        "s = 0\n",
        "\n",
        "for train, test in fold_idx:\n",
        "  X_train, X_test = X[train], X[test]\n",
        "  y_train, y_test = y[train], y[test]\n",
        "\n",
        "  model = build_baseline()\n",
        "  model.compile(optimizer = RMSprop(learning_rate=1e-5) , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "  model.fit(X_train, y_train, epochs=700, verbose=False)\n",
        "\n",
        "  print(f'Model evaluation #{s}:')\n",
        "  score = model.evaluate(X_test, y_test)\n",
        "  print('Test loss:', score[0]) \n",
        "  print('Test accuracy:', score[1])\n",
        "    \n",
        "  s += 1"
      ],
      "metadata": {
        "id": "c5aIXZ3ffpSb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Analisis preliminar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPA5ASJu2dBsiJf7KFjTJih"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}